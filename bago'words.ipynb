{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's implement the 2003 Bag Of Words Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data:\n",
    "names = open(\"names.txt\").read().splitlines()\n",
    "print(f\"{len(names)=}\")\n",
    "\n",
    "# Build Vocab\n",
    "itos = {i+1:s for i,s in enumerate(sorted(set(\"\".join(names))))}\n",
    "itos[0] = '.'\n",
    "stoi = {s:i for i,s in itos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Set Creation:\n",
    "x, y = [], []\n",
    "context_len = 3\n",
    "xchar, ychar = [], []\n",
    "buff = [0]*context_len\n",
    "buff = [itos[b] for b in buff]\n",
    "for name in names:\n",
    "    augmented_name = buff + list(name) + ['.']\n",
    "    for i in range(len(augmented_name)-context_len):\n",
    "        xi = augmented_name[i:i+context_len ]\n",
    "        yi = augmented_name[i+context_len]\n",
    "        #print(f\"{xi} -------> {yi}\")\n",
    "        xchar.append(xi)\n",
    "        ychar.append(yi)\n",
    "        x.append([stoi[d] for d in xi])\n",
    "        y.append(stoi[yi])\n",
    "\n",
    "print(len(x)), print(len(y))\n",
    "print(len(xchar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tensors:\n",
    "X = torch.tensor(x)\n",
    "Y = torch.tensor(y)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create the embeddings\n",
    "C = torch.rand((27,2))\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create the NN\n",
    "Xtr = torch.cat(torch.unbind(emb,1),dim=1)\n",
    "print(Xtr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1 has 100 neurons\n",
    "# Layer 2 is Softmax\n",
    "# 6 --> 100 --> 27 --> Softmax\n",
    "\n",
    "n1 = 100\n",
    "n2 = 200\n",
    "n3 = 27\n",
    "layers = [n1,n2,n3]\n",
    "\n",
    "def paramsetting(prev,layers):\n",
    "        W = []\n",
    "        b = []\n",
    "        for layer in layers:\n",
    "            W.append(torch.rand((prev,layer),requires_grad=True))\n",
    "            b.append(torch.rand((layer),requires_grad=True))\n",
    "            prev = layer\n",
    "        return W,b\n",
    "\n",
    "\n",
    "def mainloop(X,Y, layers,iterations = 100, step_size = 0.9):\n",
    "    C = torch.rand((27,2),requires_grad=True)\n",
    "    W,b = paramsetting(6,layers)\n",
    "    losses = []\n",
    "\n",
    "    def forward(C, W,b):\n",
    "        emb = C[X]\n",
    "        H = torch.tanh(emb.view(-1,6))\n",
    "        for Wi,bi in zip(W,b):\n",
    "            H = torch.tanh(H@Wi + bi)\n",
    "        loss = F.cross_entropy(H,Y)\n",
    "        return loss\n",
    "\n",
    "    def backward(loss):\n",
    "        params = [C] + W + b\n",
    "        for param in params:\n",
    "            param.grad = None\n",
    "        loss.backward()\n",
    "        for param in params:\n",
    "            param.data += -step_size * param.grad\n",
    "        \n",
    "        return C, W,b\n",
    "    \n",
    "    # return backward(forward(C,W,b))\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        loss = forward(C,W,b)\n",
    "        losses.append(loss.data)\n",
    "        print(f\"{loss=}\")\n",
    "        C,W,b = backward(loss)\n",
    "    \n",
    "    return losses\n",
    "\n",
    "#losses = mainloop(X,Y,[100,27])\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
